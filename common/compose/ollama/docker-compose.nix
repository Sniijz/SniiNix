# Auto-generated using compose2nix v0.3.1.
{
  pkgs,
  lib,
  config,
  ...
}: let
  cfg = config.customModules.ollama;
in {
  options.customModules.ollama = {
    enable = lib.mkOption {
      type = lib.types.bool;
      default = false;
      description = ''
        whether to enable ollama globally or not
      '';
    };
  };
  config = lib.mkIf cfg.enable {
    # Runtime
    virtualisation.docker = {
      enable = true;
      autoPrune.enable = true;
    };
    virtualisation.oci-containers.backend = "docker";

    # Containers
    virtualisation.oci-containers.containers."ollama-ollama" = {
      image = "ollama/ollama:rocm";
      volumes = [
        "/home/sniijz/.docker/volumes/ollama:/root/.ollama:rw"
      ];
      ports = [
        "11434:11434/tcp"
      ];
      log-driver = "journald";
      extraOptions = [
        "--device=/dev/dri:/dev/dri:rwm"
        "--device=/dev/kfd:/dev/kfd:rwm"
        "--network-alias=ollama"
        "--network=ollama_default"
      ];
    };
    systemd.services."docker-ollama-ollama" = {
      serviceConfig = {
        Restart = lib.mkOverride 90 "no";
      };
      after = [
        "docker-network-ollama_default.service"
      ];
      requires = [
        "docker-network-ollama_default.service"
      ];
      partOf = [
        "docker-compose-ollama-root.target"
      ];
      wantedBy = [
        "docker-compose-ollama-root.target"
      ];
    };
    virtualisation.oci-containers.containers."open-webui" = {
      image = "ghcr.io/open-webui/open-webui:main";
      environment = {
        "OLLAMA_BASE_URL" = "http://ollama:11434";
        "WEBUI_SECRET_KEY" = "";
      };
      volumes = [
        "/home/sniijz/.docker/volumes/open-webui:/app/backend/data:rw"
      ];
      ports = [
        "3000:8080/tcp"
      ];
      dependsOn = [
        "ollama-ollama"
      ];
      log-driver = "journald";
      extraOptions = [
        "--add-host=host.docker.internal:host-gateway"
        "--network-alias=open-webui"
        "--network=ollama_default"
      ];
    };
    systemd.services."docker-open-webui" = {
      serviceConfig = {
        Restart = lib.mkOverride 90 "always";
        RestartMaxDelaySec = lib.mkOverride 90 "1m";
        RestartSec = lib.mkOverride 90 "100ms";
        RestartSteps = lib.mkOverride 90 9;
      };
      after = [
        "docker-network-ollama_default.service"
      ];
      requires = [
        "docker-network-ollama_default.service"
      ];
      partOf = [
        "docker-compose-ollama-root.target"
      ];
      wantedBy = [
        "docker-compose-ollama-root.target"
      ];
    };

    # Networks
    systemd.services."docker-network-ollama_default" = {
      path = [pkgs.docker];
      serviceConfig = {
        Type = "oneshot";
        RemainAfterExit = true;
        ExecStop = "docker network rm -f ollama_default";
      };
      script = ''
        docker network inspect ollama_default || docker network create ollama_default
      '';
      partOf = ["docker-compose-ollama-root.target"];
      wantedBy = ["docker-compose-ollama-root.target"];
    };

    # Builds
    systemd.services."docker-build-open-webui" = {
      path = [pkgs.docker pkgs.git];
      serviceConfig = {
        Type = "oneshot";
        TimeoutSec = 300;
      };
      script = ''
        cd /home/sniijz/Code/SniiNix/Barbatos/compose/ollama
        docker build -t ghcr.io/open-webui/open-webui:main --build-arg OLLAMA_BASE_URL=/ollama .
      '';
    };

    # Root service
    # When started, this will automatically create all resources and start
    # the containers. When stopped, this will teardown all resources.
    systemd.targets."docker-compose-ollama-root" = {
      unitConfig = {
        Description = "Root target generated by compose2nix.";
      };
      wantedBy = ["multi-user.target"];
    };
  };
}
